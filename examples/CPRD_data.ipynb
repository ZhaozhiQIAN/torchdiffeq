{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import numpy as np\n",
    "import time\n",
    "import importlib\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint_adjoint as odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint as dto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ode_models' from '/alt/applic/user-maint/zq224/WS/torchdiffeq/examples/ode_models.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ode_models\n",
    "importlib.reload(ode_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:' + str(1) if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_TYPE = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['creatinine', 'dbp', 'sbp', 'tchol'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pds.read_csv('data/cprd_full_4_markers.csv.gz', compression='gzip')\n",
    "bio_markers = dat.columns[2:]\n",
    "\n",
    "for b in bio_markers:\n",
    "    dat[b] = (dat[b] - dat[b].mean()) / dat[b].std()\n",
    "\n",
    "bio_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patid</th>\n",
       "      <th>ts</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>dbp</th>\n",
       "      <th>sbp</th>\n",
       "      <th>tchol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.196299</td>\n",
       "      <td>2.501302</td>\n",
       "      <td>1.808223</td>\n",
       "      <td>1.934243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1025</td>\n",
       "      <td>2.871233</td>\n",
       "      <td>-1.450525</td>\n",
       "      <td>2.410151</td>\n",
       "      <td>1.584469</td>\n",
       "      <td>1.675120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1025</td>\n",
       "      <td>3.197260</td>\n",
       "      <td>-1.450525</td>\n",
       "      <td>0.495972</td>\n",
       "      <td>-0.597133</td>\n",
       "      <td>-0.311484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1025</td>\n",
       "      <td>6.841096</td>\n",
       "      <td>-1.238670</td>\n",
       "      <td>1.042880</td>\n",
       "      <td>0.521637</td>\n",
       "      <td>-0.225110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1025</td>\n",
       "      <td>8.484932</td>\n",
       "      <td>-1.238670</td>\n",
       "      <td>0.131367</td>\n",
       "      <td>-0.149625</td>\n",
       "      <td>-0.743355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patid        ts  creatinine       dbp       sbp     tchol\n",
       "0   1025  0.000000   -1.196299  2.501302  1.808223  1.934243\n",
       "1   1025  2.871233   -1.450525  2.410151  1.584469  1.675120\n",
       "2   1025  3.197260   -1.450525  0.495972 -0.597133 -0.311484\n",
       "3   1025  6.841096   -1.238670  1.042880  0.521637 -0.225110\n",
       "4   1025  8.484932   -1.238670  0.131367 -0.149625 -0.743355"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dict = dict()\n",
    "\n",
    "dat_grouped = dat.groupby('patid')\n",
    "\n",
    "for name,group in dat_grouped:\n",
    "    t = group['ts'].values\n",
    "    x = group[bio_markers].values\n",
    "    len_t = len(t)\n",
    "    dim = x.shape[1]\n",
    "    x_reshaped = x.reshape(len_t, 1, 1, dim)\n",
    "    dat_dict[str(name)] = dict(t=torch.tensor(t, dtype=D_TYPE), x=torch.tensor(x_reshaped, dtype=D_TYPE))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(dat_dict, fold=5, seed=666):\n",
    "    random.seed(seed)\n",
    "    eids = list(dat_dict.keys())\n",
    "    eid_set = set(eids)\n",
    "    random.shuffle(eids)\n",
    "\n",
    "    fold_list = list()\n",
    "    for i in range(fold):\n",
    "        eid_test = eids[i::fold]\n",
    "        dat_test_fold = { k: dat_dict[k] for k in eid_test }\n",
    "\n",
    "        eid_remain = list(eid_set - set(eid_test))\n",
    "        eid_val = eid_remain[::10]\n",
    "        dat_val_fold = { k: dat_dict[k] for k in eid_val }\n",
    "\n",
    "        eid_train = list(set(eid_remain) - set(eid_val))\n",
    "\n",
    "        dat_train_fold = { k: dat_dict[k] for k in eid_train }\n",
    "        fold_dict = {'train': dat_train_fold, 'val': dat_val_fold, 'test': dat_test_fold}\n",
    "        fold_list.append(fold_dict)\n",
    "\n",
    "    return fold_list\n",
    "\n",
    "# testit\n",
    "# t = set()\n",
    "# for i in range(5):\n",
    "#     print(len(dat_folds[i]['train'].keys()), len(dat_folds[i]['val'].keys()), len(dat_folds[i]['test'].keys()))\n",
    "#     print(len(set(dat_folds[i]['train'].keys()).union(set(dat_folds[i]['val'].keys()),set(dat_folds[i]['test'].keys()))))\n",
    "#     t=t.union(set(dat_folds[i]['test'].keys()))\n",
    "# len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_folds = get_fold(dat_dict, fold=5, seed=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dat_dict, batch_size, seed=42):\n",
    "    random.seed(seed)\n",
    "    eids = random.sample(list(dat_dict.keys()), batch_size)\n",
    "    t_list = [dat_dict[e]['t'] for e in eids]\n",
    "    t_max = max([len(x) for x in t_list])\n",
    "    t_padded = [F.pad(x, (0, t_max - len(x)), \"constant\", -1.).reshape((-1, 1)) for x in t_list]\n",
    "    t_tensor = torch.cat(t_padded, dim=1)\n",
    "    t_mask = t_tensor >= 0\n",
    "    \n",
    "    x_list = [dat_dict[e]['x'] for e in eids]\n",
    "    x_padded = [F.pad(i, (0,0,0,0,0,0,0,t_max - i.shape[0]), \"constant\", -1.) for i in x_list]\n",
    "    x_tensor = torch.cat(x_padded, dim=1)\n",
    "    x_mask = x_tensor >= 0\n",
    "    x0_tensor = x_tensor[0, ...]\n",
    "    \n",
    "    return t_tensor, x_tensor, x0_tensor, t_mask, x_mask, eids\n",
    "\n",
    "def get_all(dat_dict, seed=42):\n",
    "    eids = list(dat_dict.keys())\n",
    "    t_list = [dat_dict[e]['t'] for e in eids]\n",
    "    t_max = max([len(x) for x in t_list])\n",
    "    t_padded = [F.pad(x, (0, t_max - len(x)), \"constant\", -1.).reshape((-1, 1)) for x in t_list]\n",
    "    t_tensor = torch.cat(t_padded, dim=1)\n",
    "    t_mask = t_tensor >= 0\n",
    "    \n",
    "    x_list = [dat_dict[e]['x'] for e in eids]\n",
    "    x_padded = [F.pad(i, (0,0,0,0,0,0,0,t_max - i.shape[0]), \"constant\", -1.) for i in x_list]\n",
    "    x_tensor = torch.cat(x_padded, dim=1)\n",
    "    x_mask = x_tensor >= 0\n",
    "    x0_tensor = x_tensor[0, ...]\n",
    "    \n",
    "    return t_tensor, x_tensor, x0_tensor, t_mask, x_mask, eids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, y, y0, t_mask, y_mask, eids = get_batch(dat_folds[0]['train'], batch_size=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9626)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, y, y0, t_mask, y_mask, eids = get_batch(dat_dict, batch_size=7000)\n",
    "torch.mean(torch.abs(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM without time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_utils' from '/alt/applic/user-maint/zq224/WS/torchdiffeq/examples/training_utils.py'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baseline_models as baseline\n",
    "import training_utils\n",
    "\n",
    "importlib.reload(training_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "niters = 1000\n",
    "test_freq = 100\n",
    "batch_size = 500\n",
    "input_dim = output_dim = 4\n",
    "n_hidden = 50\n",
    "\n",
    "base_lstm = baseline.BaselineLSTM(input_dim, n_hidden, output_dim)\n",
    "optimizer = optim.Adam(base_lstm.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_lstm_loss_func(t, y, y0, t_mask, y_mask, eids):\n",
    "    y_pred = base_lstm(y0, t)\n",
    "    loss = torch.mean(torch.abs(y_pred[y_mask.squeeze()] - y[y_mask]))\n",
    "    return loss\n",
    "\n",
    "def base_lstm_save_func():\n",
    "    model_path = 'models/cprd_lstm_no_time.pth'\n",
    "    torch.save(base_lstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0100 | Total Loss 0.527168\n",
      "Iter 0200 | Total Loss 0.452818\n",
      "Iter 0300 | Total Loss 0.420922\n",
      "Iter 0400 | Total Loss 0.401545\n",
      "Iter 0500 | Total Loss 0.389461\n",
      "Iter 0600 | Total Loss 0.382782\n",
      "Iter 0700 | Total Loss 0.378658\n",
      "Iter 0800 | Total Loss 0.376341\n",
      "Iter 0900 | Total Loss 0.373735\n",
      "Iter 1000 | Total Loss 0.371715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.3717), 62.42432188987732)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_utils.training_loop(niters, \n",
    "                    dat_folds[0], \n",
    "                    batch_size, \n",
    "                    optimizer, \n",
    "                    test_freq, \n",
    "                    base_lstm_loss_func, \n",
    "                    base_lstm_save_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "niters = 5000\n",
    "test_freq = 100\n",
    "batch_size = 500\n",
    "input_dim = output_dim = 4\n",
    "n_hidden = 50\n",
    "model_path = 'models/cprd_lstm.pth'\n",
    "\n",
    "base_time_lstm = baseline.BaselineTimeLSTM(input_dim, n_hidden, output_dim)\n",
    "\n",
    "optimizer = optim.Adam(base_time_lstm.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_time_lstm_loss_func(t, y, y0, t_mask, y_mask, eids):\n",
    "    y_pred = base_time_lstm(y0, t)\n",
    "    loss = torch.mean(torch.abs(y_pred[y_mask.squeeze()] - y[y_mask]))\n",
    "    return loss\n",
    "\n",
    "def base_time_lstm_save_func():\n",
    "    model_path = 'models/cprd_lstm.pth'\n",
    "    torch.save(base_time_lstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_utils.training_loop(niters, \n",
    "                    dat_folds[0], \n",
    "                    batch_size, \n",
    "                    optimizer, \n",
    "                    test_freq, \n",
    "                    base_time_lstm_loss_func, \n",
    "                    base_time_lstm_save_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Neural ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "niters = 100\n",
    "batch_size = 500\n",
    "step_size = 1./12\n",
    "test_freq = 10\n",
    "\n",
    "# vanila Neural ODE\n",
    "func0 = ode_models.ODEFunc0(dim_y=4)\n",
    "optimizer = optim.Adam(func0.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vanilla_ode_loss_func(t, y, y0, t_mask, y_mask, eids):\n",
    "    pred_y = dto(func0, y0, t, method='euler_par', options={'step_size': step_size})\n",
    "    loss = torch.mean(torch.abs(pred_y[y_mask] - y[y_mask]))\n",
    "    return loss\n",
    "\n",
    "def Vanilla_ode_save_func():\n",
    "    model_path = 'models/vanilla_ode.pth'\n",
    "    torch.save(func0.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0010 | Total Loss 0.527961\n",
      "Iter 0020 | Total Loss 0.456916\n",
      "Iter 0030 | Total Loss 0.422552\n",
      "Iter 0040 | Total Loss 0.404244\n",
      "Iter 0050 | Total Loss 0.394447\n",
      "Iter 0060 | Total Loss 0.388240\n",
      "Iter 0070 | Total Loss 0.384390\n",
      "Iter 0080 | Total Loss 0.381673\n",
      "Iter 0090 | Total Loss 0.379925\n",
      "Iter 0100 | Total Loss 0.378580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.3786), 239.4606318473816)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_utils.training_loop(niters, \n",
    "                    dat_folds[0], \n",
    "                    batch_size, \n",
    "                    optimizer, \n",
    "                    test_freq, \n",
    "                    Vanilla_ode_loss_func, \n",
    "                    Vanilla_ode_save_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "niters = 100\n",
    "batch_size = 500\n",
    "step_size = 1./12\n",
    "test_freq = 10\n",
    "\n",
    "# augmented Neural ODE\n",
    "func_aug = ode_models.ODEFuncAug(dim_y=4, dim_aug=4)\n",
    "optimizer = optim.Adam(func_aug.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_ode_loss_func(t, y, y0, t_mask, y_mask, eids):\n",
    "    y0_aug = F.pad(y0, (0, func_aug.dim_aug, 0, 0, 0, 0), \"constant\", 0.)\n",
    "    pred_y = dto(func_aug, y0_aug, t, method='euler_par', options={'step_size': step_size})\n",
    "    pred_y = pred_y[..., :func_aug.dim_y]\n",
    "    loss = torch.mean(torch.abs(pred_y[y_mask] - y[y_mask]))\n",
    "    return loss\n",
    "\n",
    "def augmented_ode_save_func():\n",
    "    model_path = 'models/augmented_ode.pth'\n",
    "    torch.save(func_aug.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0010 | Total Loss 0.480909\n",
      "Iter 0020 | Total Loss 0.426202\n",
      "Iter 0030 | Total Loss 0.406207\n",
      "Iter 0040 | Total Loss 0.395764\n",
      "Iter 0050 | Total Loss 0.390499\n",
      "Iter 0060 | Total Loss 0.386622\n",
      "Iter 0070 | Total Loss 0.384260\n",
      "Iter 0080 | Total Loss 0.382188\n",
      "Iter 0090 | Total Loss 0.380931\n",
      "Iter 0100 | Total Loss 0.379610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.3796), 264.3959217071533)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_utils.training_loop(niters, \n",
    "                    dat_folds[0], \n",
    "                    batch_size, \n",
    "                    optimizer, \n",
    "                    test_freq, \n",
    "                    augmented_ode_loss_func, \n",
    "                    augmented_ode_save_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-Order ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "niters = 100\n",
    "batch_size = 500\n",
    "step_size = 1./12\n",
    "test_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = ode_models.HigherOrderOde(dat_dict, batch_size=batch_size, dim=4, order=2, hidden_size=50)\n",
    "func.init_cond_mat.requires_grad = False\n",
    "optimizer = optim.Adam(func.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higher_ode_loss_func(t, y, y0, t_mask, y_mask, eids):\n",
    "    func.set_init_cond(eids)\n",
    "    init_zeros = torch.zeros_like(func.init_cond)\n",
    "    \n",
    "    pred_y = dto(func, init_zeros, t, method='euler_par', options={'step_size': step_size})\n",
    "    pred_y_final = (pred_y  + func.init_cond)[..., :func.dim]\n",
    "    \n",
    "    loss = torch.mean(torch.abs(pred_y_final[y_mask] - y[y_mask]))\n",
    "    return loss\n",
    "\n",
    "def higher_ode_save_func():\n",
    "    model_path = 'models/higher_ode.pth'\n",
    "    torch.save(func.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0010 | Total Loss 2.721154\n",
      "Iter 0020 | Total Loss 2.034932\n",
      "Iter 0030 | Total Loss 1.702108\n",
      "Iter 0040 | Total Loss 1.508700\n",
      "Iter 0050 | Total Loss 1.387567\n",
      "Iter 0060 | Total Loss 1.299232\n",
      "Iter 0070 | Total Loss 1.229783\n",
      "Iter 0080 | Total Loss 1.170778\n",
      "Iter 0090 | Total Loss 1.124129\n",
      "Iter 0100 | Total Loss 1.084185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.0842), 254.95494604110718)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_utils.training_loop(niters, \n",
    "                    dat_folds[0], \n",
    "                    batch_size, \n",
    "                    optimizer, \n",
    "                    test_freq, \n",
    "                    higher_ode_loss_func, \n",
    "                    higher_ode_save_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7702)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(func.init_cond_mat[:, :, 4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7975)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(func.init_cond_mat[:, :, :4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0050 | Total Loss 0.426231\n",
      "Iter 0100 | Total Loss 0.597094\n",
      "Iter 0150 | Total Loss 0.583271\n",
      "Iter 0200 | Total Loss 1.400030\n",
      "Iter 0250 | Total Loss 0.738257\n",
      "Iter 0300 | Total Loss 0.420469\n",
      "Iter 0350 | Total Loss 0.611337\n",
      "Iter 0400 | Total Loss 0.443519\n",
      "Iter 0450 | Total Loss 0.491005\n",
      "Iter 0500 | Total Loss 0.892621\n",
      "Iter 0550 | Total Loss 0.768308\n",
      "Iter 0600 | Total Loss 0.525871\n",
      "Iter 0650 | Total Loss 0.453953\n",
      "Iter 0700 | Total Loss 1.970526\n",
      "Iter 0750 | Total Loss 0.988136\n",
      "Iter 0800 | Total Loss 2.543571\n",
      "Iter 0850 | Total Loss 1.738551\n",
      "Iter 0900 | Total Loss 0.450546\n",
      "Iter 0950 | Total Loss 0.405119\n",
      "Iter 1000 | Total Loss 0.566877\n",
      "Iter 1050 | Total Loss 0.449112\n",
      "Iter 1100 | Total Loss 0.478447\n",
      "Iter 1150 | Total Loss 0.420794\n",
      "Iter 1200 | Total Loss 0.375969\n",
      "Iter 1250 | Total Loss 0.641680\n",
      "Iter 1300 | Total Loss 0.411319\n",
      "Iter 1350 | Total Loss 0.385653\n",
      "Iter 1400 | Total Loss 0.409560\n",
      "Iter 1450 | Total Loss 0.422992\n",
      "Iter 1500 | Total Loss 0.390408\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "\n",
    "start = time.time()\n",
    "for itr in range(1, niters + 1):\n",
    "    \n",
    "    t, y, y0, t_mask, y_mask, eids = get_batch(dat_dict, batch_size, itr+500)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    func.set_init_cond(eids)\n",
    "    init_zeros = torch.zeros_like(func.init_cond)\n",
    "    \n",
    "    pred_y = dto(func, init_zeros, t, method='euler_par', options={'step_size': step_size})\n",
    "    pred_y_final = (pred_y  + func.init_cond)[..., :func.dim]\n",
    "    \n",
    "    loss = torch.mean(torch.abs(pred_y_final[y_mask] - y[y_mask]))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if itr % test_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            print('Iter {:04d} | Total Loss {:.6f}'.format(itr, loss.item()))\n",
    "            ii += 1\n",
    "\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/cprd_ho2.pth'\n",
    "torch.save(func.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func1 = ode_models.HigherOrderOde(dat_dict,batch_size=batch_size, dim=4, order=2, hidden_size=50)\n",
    "# func1.load_state_dict(torch.load(model_path))\n",
    "# func1.eval()\n",
    "# func1.init_cond_mat.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.17963133653005"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end-start)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr=498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, y, y0, t_mask, y_mask, eids = get_batch(dat_dict, batch_size, itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8423206'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': tensor([0.0000, 3.1205, 4.7178]),\n",
       " 'x': tensor([[[[0.4524, 2.7864, 2.9481, 1.3142]]],\n",
       " \n",
       " \n",
       "         [[[0.1569, 1.9626, 1.4286, 0.2870]]],\n",
       " \n",
       " \n",
       "         [[[0.7479, 1.6880, 1.6537, 0.8006]]]])}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_dict['14260073']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4524, 2.7864, 2.9481, 1.3142]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5238)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.array([func.eid_to_id[x] for x in eids])\n",
    "id_torch = torch.from_numpy(idx)\n",
    "#  self.init_cond = self.init_cond_mat[id_torch, ...]\n",
    "id_torch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4512,  2.7882,  2.9492,  1.3124, -0.0830, -0.2435, -0.4933, -0.3075]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond_mat[5238]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1238, -0.6072, -1.0318,  0.8855, -0.1671,  0.3526,  0.2405, -0.1994]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7010, 1, 8])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_untrain = ode_models.HigherOrderOde(dat_dict,batch_size=batch_size, dim=4, order=2, hidden_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(func.init_cond_mat[..., :4] - func_untrain.init_cond_mat[..., :4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1154,  0.6854,  1.9798,  2.4262],\n",
       "        [-1.1180,  0.0436, -0.2041,  0.8874],\n",
       "        [ 0.4524, -0.5087, -0.8788, -0.2265],\n",
       "        [ 2.0107, -0.1345,  0.5280,  0.5414],\n",
       "        [ 0.1557, -0.3421,  0.3031, -0.1577]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond_mat[:5, 0, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0964,  0.6812,  1.9914,  2.4268],\n",
       "        [-1.1096,  0.0405, -0.2035,  0.8862],\n",
       "        [ 0.4524, -0.5087, -0.8788, -0.2265],\n",
       "        [ 2.0144, -0.1426,  0.5282,  0.5438],\n",
       "        [ 0.1569, -0.3256,  0.3031, -0.1409]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_untrain.init_cond_mat[:5, 0, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6105,  0.4214,  2.3506, -0.3816],\n",
       "        [-0.0939,  0.3392,  0.6464, -0.7820],\n",
       "        [-1.3570,  0.3796, -0.4085,  0.0888],\n",
       "        [-0.0635, -0.4829, -0.3766, -0.1169],\n",
       "        [-0.1704,  0.3768, -0.1794,  0.4243]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond_mat[:5, 0, -4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5927,  0.4283,  2.3702, -0.4005],\n",
       "        [-0.0888,  0.3464,  0.6390, -0.7918],\n",
       "        [-1.3570,  0.3796, -0.4085,  0.0888],\n",
       "        [-0.0617, -0.4903, -0.3837, -0.1250],\n",
       "        [-0.1813,  0.3930, -0.1933,  0.4411]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_untrain.init_cond_mat[:5, 0, -4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 500\n",
      "Processed: 1000\n",
      "Processed: 1500\n",
      "Processed: 2000\n",
      "Processed: 2500\n",
      "Processed: 3000\n",
      "Processed: 3500\n",
      "Processed: 4000\n",
      "Processed: 4500\n",
      "Processed: 5000\n",
      "Processed: 5500\n",
      "Processed: 6000\n",
      "Processed: 6500\n",
      "Processed: 7000\n"
     ]
    }
   ],
   "source": [
    "n_processed = 0\n",
    "step_size = 1./12\n",
    "\n",
    "s = time.time()\n",
    "for eid, v in dat_dict.items():\n",
    "    t = v['t']\n",
    "    x = v['x']\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    func.set_init_cond([eid])\n",
    "    init_zeros = torch.zeros_like(func.init_cond)\n",
    "    \n",
    "#     pred_y = odeint(func, init_zeros, t)\n",
    "    pred_y = dto(func, init_zeros, t, method='euler', options={'step_size': step_size})\n",
    "    \n",
    "    pred_y_final = pred_y  + func.init_cond\n",
    "    loss = torch.mean(torch.abs(pred_y_final[..., :func.dim] - x))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    n_processed += 1\n",
    "    \n",
    "    if n_processed % 500 == 0:\n",
    "        print('Processed:', n_processed)\n",
    "#     if n_processed > 100:\n",
    "#         break\n",
    "e = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175.36765384674072"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_zeros.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[100.0000,  91.0000, 128.0000,   6.4000, -11.1027,  -1.3878,   5.5513,\n",
       "           -2.6369]]], requires_grad=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = odeint(func, init_zeros, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HigherOrderOde' object has no attribute 'set_init_cond'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-66047e822195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_init_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0minit_zeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/alt/applic/user-maint/zq224/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HigherOrderOde' object has no attribute 'set_init_cond'"
     ]
    }
   ],
   "source": [
    "v = dat_dict['1092']\n",
    "\n",
    "t = v['t']\n",
    "x = v['x']\n",
    "\n",
    "optimizer.zero_grad()\n",
    "func.set_init_cond(eid, t, x)\n",
    "init_zeros = torch.zeros_like(func.init_cond)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = odeint(func, init_zeros, t)\n",
    "pred_y_final = pred_y + func.init_cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean(torch.abs(pred_y_final[..., :func.dim] - x))\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, ...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid_list = list(dat_dict.keys())\n",
    "eid_to_id = dict(zip(eid_list, range(len(eid_list))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': tensor([0.0000, 0.8548, 4.8959]),\n",
       " 'x': tensor([[[[ 86.0000,  86.0000, 174.0000,   7.6000]]],\n",
       " \n",
       " \n",
       "         [[[ 74.0000,  90.0000, 210.0000,   7.2000]]],\n",
       " \n",
       " \n",
       "         [[[ 88.0000,  82.0000, 140.0000,   5.6000]]]])}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_dict['1092']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': tensor([0.0000, 2.3781, 5.7644]),\n",
       " 'x': tensor([[[[ 62.0000,  79.0000, 135.0000,   5.8000]]],\n",
       " \n",
       " \n",
       "         [[[ 57.0000,  88.0000, 162.0000,   3.6000]]],\n",
       " \n",
       " \n",
       "         [[[ 74.0000,  78.0000, 146.0000,   4.8000]]]])}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_dict['3259']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1, 4])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
