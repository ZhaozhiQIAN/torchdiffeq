{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import numpy as np\n",
    "import time\n",
    "import importlib\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint_adjoint as odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint as dto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ode_models' from '/alt/applic/user-maint/zq224/WS/torchdiffeq/examples/ode_models.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ode_models\n",
    "importlib.reload(ode_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_utils' from '/alt/applic/user-maint/zq224/WS/torchdiffeq/examples/training_utils.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baseline_models as baseline\n",
    "import training_utils\n",
    "\n",
    "importlib.reload(training_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'GRUD' from '/alt/applic/user-maint/zq224/WS/torchdiffeq/examples/GRUD.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import GRUD\n",
    "importlib.reload(GRUD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:' + str(0) if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_TYPE = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dict = training_utils.get_data('data/cprd_sample_5_obs.csv.gz', normalize=False)\n",
    "dat_folds = training_utils.get_fold(dat_dict, fold=5, seed=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, y, y0, t_mask, y_mask, eids = training_utils.get_batch(dat_folds[0]['train'], batch_size=70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105, 70, 1, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_from_eids(dat_dict, eids):\n",
    "    t_list = [dat_dict[e]['t'] for e in eids]\n",
    "    t_max = max([len(x) for x in t_list])\n",
    "    t_padded = [F.pad(x, (0, t_max - len(x)), \"constant\", -1.).reshape((-1, 1)) for x in t_list]\n",
    "    t_tensor = torch.cat(t_padded, dim=1)\n",
    "    t_mask = t_tensor >= 0\n",
    "\n",
    "    x_list = [dat_dict[e]['x'] for e in eids]\n",
    "    x_padded = [F.pad(i, (0, 0, 0, 0, 0, 0, 0, t_max - i.shape[0]), \"constant\", -1.) for i in x_list]\n",
    "    x_tensor = torch.cat(x_padded, dim=1)\n",
    "    x_mask = x_tensor >= 0\n",
    "    x0_tensor = x_tensor[0, ...]\n",
    "\n",
    "    return t_tensor, x_tensor, x0_tensor, t_mask, x_mask, eids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eids = list(dat_dict.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_list = [dat_dict[e]['t'] for e in eids]\n",
    "x_list = [dat_dict[e]['x'] for e in eids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([172])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vec = torch.cat(t_list)\n",
    "t_tensor, _ = torch.sort(torch.unique(t_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([167])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dict = {str(t): i for i, t in enumerate(t_tensor.numpy())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 1, 1, 9])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.zeros((t_tensor.shape[0], len(eids), 1, x_list[0].shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([167, 5, 1, 9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0\n",
      "0 1.5863013 25\n",
      "0 1.7260274 28\n",
      "0 1.7534246 29\n",
      "0 2.1945205 31\n",
      "0 2.2328768 32\n",
      "0 3.1342466 43\n",
      "0 3.6547945 51\n",
      "0 3.671233 52\n",
      "0 3.9123287 57\n",
      "0 4.764384 69\n",
      "0 4.786301 70\n",
      "0 4.7945204 71\n",
      "0 4.810959 74\n",
      "0 4.928767 76\n",
      "0 4.939726 77\n",
      "0 5.057534 79\n",
      "0 5.071233 82\n",
      "0 5.3013697 89\n",
      "0 5.6191783 90\n",
      "0 5.627397 91\n",
      "0 5.649315 92\n",
      "0 6.4136987 103\n",
      "0 6.6136985 108\n",
      "0 6.6465755 109\n",
      "0 6.6547947 110\n",
      "0 6.6657534 111\n",
      "0 7.4602737 118\n",
      "0 7.6986303 122\n",
      "0 8.150685 125\n",
      "0 8.630137 132\n",
      "0 9.660274 144\n",
      "0 10.230137 149\n",
      "0 10.249315 150\n",
      "0 10.290411 152\n",
      "0 10.29863 153\n",
      "1 0.0 0\n",
      "1 0.016438356 1\n",
      "1 0.019178081 2\n",
      "1 0.073972605 3\n",
      "1 0.09315068 4\n",
      "1 0.1890411 6\n",
      "1 0.32328767 11\n",
      "1 0.53424656 14\n",
      "1 0.59178084 15\n",
      "1 1.3452054 19\n",
      "1 1.4082192 21\n",
      "1 1.5013698 23\n",
      "1 1.5890411 26\n",
      "1 2.6136987 37\n",
      "1 3.1342466 43\n",
      "1 4.1260276 61\n",
      "1 4.131507 62\n",
      "1 5.1232877 83\n",
      "1 5.178082 84\n",
      "1 5.2246575 86\n",
      "2 0.0 0\n",
      "2 0.22739726 8\n",
      "2 1.0493151 16\n",
      "2 2.5945206 36\n",
      "2 3.2191782 45\n",
      "2 3.2986302 47\n",
      "2 3.509589 50\n",
      "2 3.7369864 53\n",
      "2 3.9671233 59\n",
      "2 4.367123 65\n",
      "2 4.5671234 68\n",
      "2 4.7972603 72\n",
      "2 5.060274 80\n",
      "2 5.287671 88\n",
      "2 5.978082 95\n",
      "2 6.208219 96\n",
      "2 6.4383564 105\n",
      "2 6.6684933 112\n",
      "2 7.2493153 116\n",
      "3 0.0 0\n",
      "3 0.36438355 12\n",
      "3 1.2219179 17\n",
      "3 1.249315 18\n",
      "3 1.3561643 20\n",
      "3 1.5260274 24\n",
      "3 2.589041 35\n",
      "3 2.6219177 38\n",
      "3 2.6657534 41\n",
      "3 3.2328768 46\n",
      "3 3.3561645 49\n",
      "3 3.7589042 54\n",
      "3 3.7917807 56\n",
      "3 4.2767124 63\n",
      "3 5.027397 78\n",
      "3 5.0657535 81\n",
      "3 5.241096 87\n",
      "3 6.293151 97\n",
      "3 6.3068495 98\n",
      "3 6.312329 99\n",
      "3 6.3863015 101\n",
      "3 6.4054794 102\n",
      "3 6.4246573 104\n",
      "3 7.019178 115\n",
      "3 7.6931505 121\n",
      "3 8.194521 126\n",
      "3 8.967123 136\n",
      "3 8.978083 137\n",
      "3 9.821918 147\n",
      "3 9.975343 148\n",
      "3 10.276712 151\n",
      "3 11.20274 161\n",
      "3 11.482192 163\n",
      "4 0.0 0\n",
      "4 0.18630137 5\n",
      "4 0.21643835 7\n",
      "4 0.24657534 9\n",
      "4 0.27123287 10\n",
      "4 0.51232874 13\n",
      "4 1.4356165 22\n",
      "4 1.7205479 27\n",
      "4 2.1643836 30\n",
      "4 2.49863 33\n",
      "4 2.5561643 34\n",
      "4 2.6273973 39\n",
      "4 2.6328766 40\n",
      "4 2.9863014 42\n",
      "4 3.1616437 44\n",
      "4 3.3452055 48\n",
      "4 3.7671232 55\n",
      "4 3.9342465 58\n",
      "4 3.9726028 60\n",
      "4 4.3232875 64\n",
      "4 4.4547944 66\n",
      "4 4.5041094 67\n",
      "4 4.8 73\n",
      "4 4.8328767 75\n",
      "4 5.2 85\n",
      "4 5.7726026 93\n",
      "4 5.8356166 94\n",
      "4 6.3561645 100\n",
      "4 6.441096 106\n",
      "4 6.5150685 107\n",
      "4 6.7178082 113\n",
      "4 6.7561646 114\n",
      "4 7.3342466 117\n",
      "4 7.6136985 119\n",
      "4 7.630137 120\n",
      "4 7.9369864 123\n",
      "4 7.9616437 124\n",
      "4 8.213698 127\n",
      "4 8.249315 128\n",
      "4 8.361644 129\n",
      "4 8.397261 130\n",
      "4 8.427398 131\n",
      "4 8.915069 133\n",
      "4 8.934247 134\n",
      "4 8.956164 135\n",
      "4 8.989041 138\n",
      "4 9.134247 139\n",
      "4 9.413698 140\n",
      "4 9.419178 141\n",
      "4 9.452055 142\n",
      "4 9.632876 143\n",
      "4 9.663013 145\n",
      "4 9.778082 146\n",
      "4 10.427398 154\n",
      "4 10.430137 155\n",
      "4 10.783562 156\n",
      "4 10.80274 157\n",
      "4 10.887671 158\n",
      "4 11.065753 159\n",
      "4 11.082191 160\n",
      "4 11.465754 162\n",
      "4 11.567123 164\n",
      "4 11.616438 165\n",
      "4 11.627398 166\n"
     ]
    }
   ],
   "source": [
    "for m in range(len(eids)):\n",
    "    tm = t_list[m].numpy()\n",
    "    for i in range(len(tm)):\n",
    "        ti = str(tm[i])\n",
    "        ind = t_dict[ti]\n",
    "        print(m, ti, ind)\n",
    "        x_tensor[ind, m, 0, :] = x_list[m][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  1.5863,  1.7260,  1.7534,  2.1945,  2.2329,  3.1342,  3.6548,\n",
       "         3.6712,  3.9123,  4.7644,  4.7863,  4.7945,  4.8110,  4.9288,  4.9397,\n",
       "         5.0575,  5.0712,  5.3014,  5.6192,  5.6274,  5.6493,  6.4137,  6.6137,\n",
       "         6.6466,  6.6548,  6.6658,  7.4603,  7.6986,  8.1507,  8.6301,  9.6603,\n",
       "        10.2301, 10.2493, 10.2904, 10.2986])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.6274)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_tensor[166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5872,     nan, -1.7097,     nan,     nan,     nan, -1.1908,     nan,\n",
       "            nan])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor[166, -1, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5872,     nan, -1.7097,     nan,     nan,     nan, -1.1908,\n",
       "              nan,     nan]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list[-1][-1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nan = torch.isnan(x_tensor)\n",
    "x_mask =  ~x_nan\n",
    "x_tensor[x_nan] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_from_eids_stack_t(dat_dict, eids):\n",
    "    t_list = [dat_dict[e]['t'] for e in eids]\n",
    "    x_list = [dat_dict[e]['x'] for e in eids]\n",
    "    t_vec = torch.cat(t_list)\n",
    "    t_tensor, _ = torch.sort(torch.unique(t_vec))\n",
    "    t_dict = {str(t): i for i, t in enumerate(t_tensor.numpy())}\n",
    "    x_tensor = torch.zeros((t_tensor.shape[0], len(eids), 1, x_list[0].shape[-1]))\n",
    "    x_mask = torch.zeros_like(x_tensor, dtype=torch.bool)\n",
    "    for m in range(len(eids)):\n",
    "        tm = t_list[m].numpy()\n",
    "        for i in range(len(tm)):\n",
    "            ti = str(tm[i])\n",
    "            ind = t_dict[ti]\n",
    "            x_tensor[ind, m, 0, :] = x_list[m][i]\n",
    "            x_mask[ind, m, 0, :] = ~torch.isnan(x_list[m][i])\n",
    "    x_tensor[torch.isnan(x_tensor)] = 0.\n",
    "    x0_tensor = x_tensor[0, ...]\n",
    "    \n",
    "    return t_tensor, x_tensor, x0_tensor, None, x_mask, eids\n",
    "\n",
    "def get_batch_stack_t(dat_dict, batch_size, seed=42):\n",
    "    random.seed(seed)\n",
    "    eids = random.sample(list(dat_dict.keys()), batch_size)\n",
    "    return get_batch_from_eids_stack_t(dat_dict, eids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, y, y0, t_mask, y_mask, eids = get_batch_stack_t(dat_dict, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5391)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(y_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1688, 100, 1, 9])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1513809)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1688 * 100 * 9 - torch.sum(y_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5391)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(y != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  ...,  True,  True,  True])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mask[:, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bool"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mask.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb_mask = torch.zeros_like(y, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb_mask[:, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((3,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 2, 1, 9])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_for_grud():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training one step\n",
    "\n",
    "# parameters\n",
    "batch_size = 6\n",
    "encode_t = 1.\n",
    "dim_y = 9\n",
    "dim_hidden = 50\n",
    "dim_decoder_mlp_hidden = 20\n",
    "\n",
    "# models\n",
    "gru = GRUD.GRUD(input_size=dim_y, hidden_size=50, output_last=True)\n",
    "lstm_decoder = baseline_models.BaselineTimeLSTM(dim_hidden, dim_hidden, dim_hidden)\n",
    "decoder = Decoder(dim_hidden, dim_y, dim_decoder_mlp_hidden)\n",
    "\n",
    "\n",
    "# data\n",
    "\n",
    "t, y, y0, t_mask, y_mask, eids = get_batch_stack_t(dat_dict, batch_size=batch_size)\n",
    "enc_step = int(torch.sum(t<encode_t))\n",
    "\n",
    "t_delta = t[1:] - t[:-1]\n",
    "t_delta = torch.cat((torch.zeros((1,)), t_delta))\n",
    "t_delta_mat = t_delta.reshape((-1, 1, 1, 1)).repeat((1, y.shape[1], 1, y.shape[-1]))\n",
    "last_y_mat = torch.cat((y[0:1, ...], y[:-1, ...]), dim=0)\n",
    "\n",
    "for i in range(1, t_delta_mat.shape[0]):\n",
    "    last_delta = t_delta_mat[i-1, ...]\n",
    "    last_mask = y_mask[i-1, ...].to(last_delta)\n",
    "    t_delta_mat[i, ...] = t_delta_mat[i, ...] + last_delta * (1 - last_mask)\n",
    "    last_y_mat[i, ...] = last_y_mat[i, ...] + last_y_mat[i-1, ...] * (1 - last_mask)\n",
    "\n",
    "y_target = y[enc_step:, ...].squeeze().to(device) # y is needed for loss\n",
    "y_target_mask = y_mask[enc_step:, ...].squeeze().to(device)\n",
    "gru_d_input = torch.cat((y, last_y_mat, y_mask.to(y), t_delta_mat), dim=2)[:enc_step, ...].permute((1, 2, 0, 3)).to(device)\n",
    "\n",
    "res = gru(gru_d_input)\n",
    "\n",
    "# tmat at decode\n",
    "t_delta_dec_mat = t_delta[enc_step:].reshape((-1, 1)).repeat((1, y.shape[1])).to(device)\n",
    "\n",
    "y_pred = lstm_decoder(res, t_delta_dec_mat)\n",
    "y_out = decoder(y_pred)\n",
    "\n",
    "y_out.shape\n",
    "\n",
    "loss = torch.mean(torch.abs(y_out[y_target_mask] - y_target[y_target_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7097055912017822"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([68, 6, 1, 9])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.9233, 0.9808])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:int(torch.sum(t<1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, y, y0, t_mask, y_mask, eids = get_batch_stack_t(dat_dict, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_delta = t[1:] - t[:-1]\n",
    "t_delta = torch.cat((torch.zeros((1,)), t_delta))\n",
    "t_delta_mat = t_delta.reshape((-1, 1, 1, 1)).repeat((1, y.shape[1], 1, y.shape[-1]))\n",
    "\n",
    "last_y_mat = torch.cat((y[0:1, ...], y[:-1, ...]), dim=0)\n",
    "\n",
    "for i in range(1, t_delta_mat.shape[0]):\n",
    "    last_delta = t_delta_mat[i-1, ...]\n",
    "    last_mask = y_mask[i-1, ...].to(last_delta)\n",
    "    t_delta_mat[i, ...] = t_delta_mat[i, ...] + last_delta * (1 - last_mask)\n",
    "    last_y_mat[i, ...] = last_y_mat[i, ...] + last_y_mat[i-1, ...] * (1 - last_mask)\n",
    "\n",
    "gru_d_input = torch.cat((y, last_y_mat, y_mask.to(y), t_delta_mat), dim=2).permute((1, 2, 0, 3))\n",
    "\n",
    "gru_d_input = gru_d_input.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_d_input.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'GRUD' from '/alt/applic/user-maint/zq224/WS/torchdiffeq/examples/GRUD.py'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(GRUD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = torch.zeros_like(y).squeeze().permute((1, 0, 2))\n",
    "\n",
    "gru = GRUD.GRUD(input_size=9, cell_size=None, hidden_size=50, X_mean=x_mean, output_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 18, 9])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = gru(gru_d_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 50])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 9])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'baseline_models' from '/alt/applic/user-maint/zq224/WS/torchdiffeq/examples/baseline_models.py'>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baseline_models\n",
    "importlib.reload(baseline_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_decoder = baseline_models.BaselineTimeLSTM(50, 50, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mat = t_delta.reshape((-1, 1)).repeat((1, y.shape[1])).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mat.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm_decoder(res, t_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 2, 50])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:' + str(0) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20, device=DEVICE):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True).to(device)\n",
    "        self.fc1 = nn.Linear(latent_dim, nhidden).to(device)\n",
    "        self.fc2 = nn.Linear(nhidden, obs_dim).to(device)\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.fc1(z)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(50, 9, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = decoder(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 2, 9])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.2255, 0.2255, 0.3304, 0.3304, 0.3304,\n",
       "        0.3304, 0.3304, 0.3304, 0.3304, 0.3304, 0.3304, 0.3304, 0.3304, 0.3304])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_y_mat[:, 0, 0, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.2255, 0.0000, 0.3304, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, 0, 0, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True, False,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mask[:, 0, 0, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 2, 1, 9])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False, False, False, False, False, False, False],\n",
       "        [False, False,  True, False, False, False,  True, False, False],\n",
       "        [False, False,  True, False, False, False,  True, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False],\n",
       "        [False, False,  True, False, False, False,  True, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False],\n",
       "        [False, False,  True, False, False, False,  True, False, False],\n",
       "        [False, False,  True, False, False, False,  True, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False],\n",
       "        [False, False,  True, False, False, False,  True, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False],\n",
       "        [False, False,  True, False, False, False,  True, False, False],\n",
       "        [False, False,  True, False, False, False,  True, False, False],\n",
       "        [False,  True, False,  True,  True, False, False,  True,  True],\n",
       "        [False, False,  True, False, False, False,  True, False, False],\n",
       "        [False,  True, False,  True,  True, False, False,  True,  True],\n",
       "        [False, False,  True, False, False, False,  True, False, False],\n",
       "        [False,  True, False,  True,  True, False, False,  True,  True]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mask[:, 1, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mat = t.reshape((-1, 1)).repeat((1, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3883, 500])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3883, 1])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vec = t.reshape((-1, 1))\n",
    "t_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mat = t_vec.repeat((1, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3883, 500])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9626)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, y, y0, t_mask, y_mask, eids = get_batch(dat_dict, batch_size=7000)\n",
    "torch.mean(torch.abs(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 1, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "niters = 5000\n",
    "test_freq = 100\n",
    "batch_size = 500\n",
    "input_dim = output_dim = 4\n",
    "n_hidden = 50\n",
    "model_path = 'models/cprd_lstm.pth'\n",
    "\n",
    "base_time_lstm = baseline.BaselineTimeLSTM(input_dim, n_hidden, output_dim)\n",
    "\n",
    "optimizer = optim.Adam(base_time_lstm.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_time_lstm_loss_func(t, y, y0, t_mask, y_mask, eids):\n",
    "    y_pred = base_time_lstm(y0, t)\n",
    "    loss = torch.mean(torch.abs(y_pred[y_mask.squeeze()] - y[y_mask]))\n",
    "    return loss\n",
    "\n",
    "def base_time_lstm_save_func():\n",
    "    model_path = 'models/cprd_lstm.pth'\n",
    "    torch.save(base_time_lstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0100 | Total Loss 0.525657\n",
      "Iter 0200 | Total Loss 0.447242\n",
      "Iter 0300 | Total Loss 0.412594\n",
      "Iter 0400 | Total Loss 0.391881\n",
      "Iter 0500 | Total Loss 0.384577\n",
      "Iter 0600 | Total Loss 0.378533\n",
      "Iter 0700 | Total Loss 0.374993\n",
      "Iter 0800 | Total Loss 0.372451\n",
      "Iter 0900 | Total Loss 0.370759\n",
      "Iter 1000 | Total Loss 0.369180\n",
      "Iter 1100 | Total Loss 0.368492\n",
      "Iter 1200 | Total Loss 0.368420\n",
      "Iter 1300 | Total Loss 0.367803\n",
      "Iter 1400 | Total Loss 0.367126\n",
      "Iter 1500 | Total Loss 0.367088\n",
      "Iter 1600 | Total Loss 0.366410\n",
      "Iter 1700 | Total Loss 0.366708\n",
      "Iter 1800 | Total Loss 0.366041\n",
      "Iter 1900 | Total Loss 0.365523\n",
      "Iter 2000 | Total Loss 0.365653\n",
      "Iter 2100 | Total Loss 0.365256\n",
      "Iter 2200 | Total Loss 0.364898\n",
      "Iter 2300 | Total Loss 0.365341\n",
      "Iter 2400 | Total Loss 0.364773\n",
      "Iter 2500 | Total Loss 0.364827\n",
      "Iter 2600 | Total Loss 0.364687\n",
      "Iter 2700 | Total Loss 0.363944\n",
      "Iter 2800 | Total Loss 0.363720\n",
      "Iter 2900 | Total Loss 0.364264\n",
      "Iter 3000 | Total Loss 0.363748\n",
      "Iter 3100 | Total Loss 0.363850\n",
      "Iter 3200 | Total Loss 0.363424\n",
      "Iter 3300 | Total Loss 0.363756\n",
      "Iter 3400 | Total Loss 0.363236\n",
      "Iter 3500 | Total Loss 0.363238\n",
      "Iter 3600 | Total Loss 0.363446\n",
      "Iter 3700 | Total Loss 0.362917\n",
      "Iter 3800 | Total Loss 0.362907\n",
      "Iter 3900 | Total Loss 0.362970\n",
      "Iter 4000 | Total Loss 0.362961\n",
      "Iter 4100 | Total Loss 0.362657\n",
      "Iter 4200 | Total Loss 0.362742\n",
      "Iter 4300 | Total Loss 0.363058\n",
      "Iter 4400 | Total Loss 0.363310\n",
      "Iter 4500 | Total Loss 0.362361\n",
      "Iter 4600 | Total Loss 0.362552\n",
      "Iter 4700 | Total Loss 0.362318\n",
      "Iter 4800 | Total Loss 0.362919\n",
      "Iter 4900 | Total Loss 0.362201\n",
      "Iter 5000 | Total Loss 0.362750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.3622), 267.44750809669495)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_utils.training_loop(niters, \n",
    "                    dat_folds[0], \n",
    "                    batch_size, \n",
    "                    optimizer, \n",
    "                    test_freq, \n",
    "                    base_time_lstm_loss_func, \n",
    "                    base_time_lstm_save_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaselineTimeLSTM(\n",
       "  (lstm): LSTM(5, 50)\n",
       "  (lin): Linear(in_features=50, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_time_lstm = baseline.BaselineTimeLSTM(input_dim, n_hidden, output_dim)\n",
    "base_time_lstm.load_state_dict(torch.load('models/cprd_lstm.pth'))\n",
    "base_time_lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_loss = base_time_lstm_loss_func(*training_utils.get_all(dat_folds[0]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3622, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## latent ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run backward lstm to infer initial condition\n",
    "\n",
    "class EncoderLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(input_dim + 1, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to output space\n",
    "        self.lin = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        # y and t are the first k observations\n",
    "        \n",
    "        batch_size = y.shape[1]\n",
    "        dim_y = y.shape[-1]\n",
    "        t_max = t.shape[0]\n",
    "        \n",
    "        t = t.reshape((-1, 1)).repeat((t_max, batch_size, 1))\n",
    "        y = y.view((t_max, batch_size, dim_y))\n",
    "        \n",
    "        y_in = torch.cat((y, t), dim=-1)\n",
    "\n",
    "        hidden = None\n",
    "        \n",
    "        for t in reversed(range(t_max)):\n",
    "            obs = y_in[t:t+1, ...]\n",
    "            out, hidden = self.lstm(obs, hidden)\n",
    "        out_linear = self.lin(out)\n",
    "        \n",
    "        return out_linear.permute((1, 0, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [2, 2, 2],\n",
       "        [3, 3, 3],\n",
       "        [1, 1, 1],\n",
       "        [2, 2, 2],\n",
       "        [3, 3, 3]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape((-1, 1)).repeat((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
    "        self.fc2 = nn.Linear(nhidden, obs_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.fc1(z)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "niters = 100\n",
    "batch_size = 100\n",
    "step_size = 1./12\n",
    "test_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(9, 50, 10)\n",
    "latent_ode = ode_models.ODEFunc0(dim_y=10)\n",
    "decoder = Decoder(10, 9, 20)\n",
    "\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(latent_ode.parameters()) + list(decoder.parameters()), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_dec_ode_loss_func(t, y, y0, t_mask, y_mask, eids):\n",
    "    init_cond = encoder(y[:1, ...], t[:1])\n",
    "    # y_mask[:2, ...] = False\n",
    "    latent_y = odeint(latent_ode, init_cond, t)\n",
    "    pred_y = decoder(latent_y)\n",
    "    loss = torch.mean(torch.abs(pred_y[y_mask] - y[y_mask]))\n",
    "    return loss\n",
    "\n",
    "def enc_dec_ode_save_func():\n",
    "    model_path = 'exp2-models/enc-dec-{}.pth'\n",
    "    torch.save(encoder.state_dict(), model_path.format('encoder'))\n",
    "    torch.save(decoder.state_dict(), model_path.format('decoder'))\n",
    "    torch.save(latent_ode.state_dict(), model_path.format('ode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0010 | Total Loss 0.758063\n",
      "Iter 0020 | Total Loss 0.754229\n",
      "Iter 0030 | Total Loss 0.751824\n",
      "Iter 0040 | Total Loss 0.751656\n",
      "Iter 0050 | Total Loss 0.749535\n",
      "Iter 0060 | Total Loss 0.750715\n",
      "Iter 0070 | Total Loss 0.747994\n",
      "Iter 0080 | Total Loss 0.746622\n",
      "Iter 0090 | Total Loss 0.744011\n",
      "Iter 0100 | Total Loss 0.742634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.7426), 1591.252745628357)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_utils.training_loop(niters, \n",
    "                    dat_folds[0], \n",
    "                    batch_size, \n",
    "                    optimizer, \n",
    "                    test_freq, \n",
    "                    enc_dec_ode_loss_func, \n",
    "                    enc_dec_ode_save_func,\n",
    "                    'stack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (fc2): Linear(in_features=20, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'models/enc-dec-{}.pth'\n",
    "\n",
    "encoder = EncoderLSTM(4, 50, 10)\n",
    "encoder.load_state_dict(torch.load(model_path.format('encoder')))\n",
    "encoder.eval()\n",
    "\n",
    "latent_ode = ode_models.ODEFunc0(dim_y=10)\n",
    "latent_ode.load_state_dict(torch.load(model_path.format('ode')))\n",
    "latent_ode.eval()\n",
    "\n",
    "decoder = Decoder(10, 4, 20)\n",
    "decoder.load_state_dict(torch.load(model_path.format('decoder')))\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3643, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_ode_loss = enc_dec_ode_loss_func(*training_utils.get_all(dat_folds[0]['test']))\n",
    "latent_ode_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FS Latent ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "niters = 2000\n",
    "batch_size = 500\n",
    "step_size = 1./12\n",
    "test_freq = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(4, 50, 10)\n",
    "fs_ode = ode_models.FSODE(input_dim=10, hidden_dim=50)\n",
    "decoder = Decoder(10, 4, 20)\n",
    "\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(fs_ode.parameters()) + list(decoder.parameters()), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_dec_fs_ode_loss_func(t, y, y0, t_mask, y_mask, eids):\n",
    "    init_cond = encoder(y[:1, ...], t[:1])\n",
    "    # y_mask[:2, ...] = False\n",
    "    latent_y = dto(fs_ode, init_cond, t, method='euler_par', options={'step_size': step_size})\n",
    "    pred_y = decoder(latent_y)\n",
    "    loss = torch.mean(torch.abs(pred_y[y_mask] - y[y_mask]))\n",
    "    return loss\n",
    "\n",
    "def enc_dec_fs_ode_save_func():\n",
    "    model_path = 'models/enc-dec-fs-{}.pth'\n",
    "    torch.save(encoder.state_dict(), model_path.format('encoder'))\n",
    "    torch.save(decoder.state_dict(), model_path.format('decoder'))\n",
    "    torch.save(fs_ode.state_dict(), model_path.format('ode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0050 | Total Loss 0.368517\n",
      "Iter 0100 | Total Loss 0.368873\n",
      "Iter 0150 | Total Loss 0.368728\n",
      "Iter 0200 | Total Loss 0.368591\n",
      "Iter 0250 | Total Loss 0.367557\n",
      "Iter 0300 | Total Loss 0.369183\n",
      "Iter 0350 | Total Loss 0.368086\n",
      "Iter 0400 | Total Loss 0.367389\n",
      "Iter 0450 | Total Loss 0.367729\n",
      "Iter 0500 | Total Loss 0.366998\n",
      "Iter 0550 | Total Loss 0.367249\n",
      "Iter 0600 | Total Loss 0.366565\n",
      "Iter 0650 | Total Loss 0.366378\n",
      "Iter 0700 | Total Loss 0.366370\n",
      "Iter 0750 | Total Loss 0.365667\n",
      "Iter 0800 | Total Loss 0.365757\n",
      "Iter 0850 | Total Loss 0.365701\n",
      "Iter 0900 | Total Loss 0.365846\n",
      "Iter 0950 | Total Loss 0.365699\n",
      "Iter 1000 | Total Loss 0.365524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.3655), 1887.9040415287018)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_utils.training_loop(niters, \n",
    "                    dat_folds[0], \n",
    "                    batch_size, \n",
    "                    optimizer, \n",
    "                    test_freq, \n",
    "                    enc_dec_fs_ode_loss_func, \n",
    "                    enc_dec_fs_ode_save_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3654, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_ode_loss = enc_dec_fs_ode_loss_func(*training_utils.get_all(dat_folds[0]['test']))\n",
    "fs_ode_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HO Latent ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "niters = 2000\n",
    "batch_size = 500\n",
    "step_size = 1./12\n",
    "test_freq = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(4, 50, 10)\n",
    "ho_ode = ode_models.HigherOrderOdeNoInit(dim=5, order=2, hidden_size=50)\n",
    "decoder = Decoder(10, 4, 20)\n",
    "\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(ho_ode.parameters()) + list(decoder.parameters()), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_dec_ho_ode_loss_func(t, y, y0, t_mask, y_mask, eids):\n",
    "    init_cond = encoder(y[:1, ...], t[:1])\n",
    "    # y_mask[:2, ...] = False\n",
    "    latent_y = dto(ho_ode, init_cond, t, method='euler_par', options={'step_size': step_size})\n",
    "    pred_y = decoder(latent_y)\n",
    "    loss = torch.mean(torch.abs(pred_y[y_mask] - y[y_mask]))\n",
    "    return loss\n",
    "\n",
    "def enc_dec_ho_ode_save_func():\n",
    "    model_path = 'models/enc-dec-ho-{}.pth'\n",
    "    torch.save(encoder.state_dict(), model_path.format('encoder'))\n",
    "    torch.save(decoder.state_dict(), model_path.format('decoder'))\n",
    "    torch.save(ho_ode.state_dict(), model_path.format('ode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0050 | Total Loss 0.600317\n",
      "Iter 0100 | Total Loss 0.549817\n",
      "Iter 0150 | Total Loss 0.518479\n",
      "Iter 0200 | Total Loss 0.498119\n",
      "Iter 0250 | Total Loss 0.479272\n",
      "Iter 0300 | Total Loss 0.458242\n",
      "Iter 0350 | Total Loss 0.435501\n",
      "Iter 0400 | Total Loss 0.420988\n",
      "Iter 0450 | Total Loss 0.410365\n",
      "Iter 0500 | Total Loss 0.398915\n",
      "Iter 0550 | Total Loss 0.386060\n",
      "Iter 0600 | Total Loss 0.381689\n",
      "Iter 0650 | Total Loss 0.378942\n",
      "Iter 0700 | Total Loss 0.377669\n",
      "Iter 0750 | Total Loss 0.375717\n",
      "Iter 0800 | Total Loss 0.375116\n",
      "Iter 0850 | Total Loss 0.374617\n",
      "Iter 0900 | Total Loss 0.373847\n",
      "Iter 0950 | Total Loss 0.372793\n",
      "Iter 1000 | Total Loss 0.373130\n",
      "Iter 1050 | Total Loss 0.371686\n",
      "Iter 1100 | Total Loss 0.372228\n",
      "Iter 1150 | Total Loss 0.371427\n",
      "Iter 1200 | Total Loss 0.371782\n",
      "Iter 1250 | Total Loss 0.370440\n",
      "Iter 1300 | Total Loss 0.370212\n",
      "Iter 1350 | Total Loss 0.370274\n",
      "Iter 1400 | Total Loss 0.369955\n",
      "Iter 1450 | Total Loss 0.369631\n",
      "Iter 1500 | Total Loss 0.369783\n",
      "Iter 1550 | Total Loss 0.368594\n",
      "Iter 1600 | Total Loss 0.368885\n",
      "Iter 1650 | Total Loss 0.369709\n",
      "Iter 1700 | Total Loss 0.368749\n",
      "Iter 1750 | Total Loss 0.369062\n",
      "Iter 1800 | Total Loss 0.368112\n",
      "Iter 1850 | Total Loss 0.368173\n",
      "Iter 1900 | Total Loss 0.367885\n",
      "Iter 1950 | Total Loss 0.367736\n",
      "Iter 2000 | Total Loss 0.367228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.3672), 2827.6357975006104)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_utils.training_loop(niters, \n",
    "                    dat_folds[0], \n",
    "                    batch_size, \n",
    "                    optimizer, \n",
    "                    test_freq, \n",
    "                    enc_dec_ho_ode_loss_func, \n",
    "                    enc_dec_ho_ode_save_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 1, 4])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2, ...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Tensors must have same number of dimensions: got 2 and 3 at /opt/conda/conda-bld/pytorch_1570910687650/work/aten/src/TH/generic/THTensor.cpp:680",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-d6a915e50098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minit_cond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/alt/applic/user-maint/zq224/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-159-2f6a5d317604>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y, t)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0my_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Tensors must have same number of dimensions: got 2 and 3 at /opt/conda/conda-bld/pytorch_1570910687650/work/aten/src/TH/generic/THTensor.cpp:680"
     ]
    }
   ],
   "source": [
    "init_cond = encoder(y[:1, ...], t[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t, y, y0, t_mask, y_mask, eids = training_utils.get_batch(dat_folds[0]['train'], batch_size=11)\n",
    "optimizer.zero_grad()\n",
    "init_cond = encoder(y[:2, ...], t[:2])\n",
    "# y_mask[:2, ...] = False\n",
    "latent_y = dto(latent_ode, init_cond, t, method='euler_par', options={'step_size': step_size})\n",
    "pred_y = decoder(latent_y)\n",
    "loss = torch.mean(torch.abs(pred_y[y_mask] - y[y_mask]))\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 11, 1, 4])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 11, 1, 10])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 11])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    t, y, y0, t_mask, y_mask, eids = training_utils.get_batch(dat_folds[0]['train'], batch_size=11)\n",
    "    opt.zero_grad()\n",
    "    init_cond = encoder(y[:2, ...], t[:2])\n",
    "    \n",
    "    pred_y = dto(latent_ode, init_cond, t, method='euler_par', options={'step_size': step_size})\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss = torch.mean(torch.abs(init_cond.squeeze() - y0.squeeze()))\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006156797520816326"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [1.8000, 1.2438, 2.1178, 0.8356, 3.2137, 0.6877, 0.9836, 3.9123, 1.0329,\n",
       "         2.1178, 1.0164],\n",
       "        [3.0247, 1.9425, 2.9260, 2.8493, 4.3616, 3.2630, 2.0904, 8.8082, 1.4384,\n",
       "         2.6301, 2.0795]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 4])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_cond.permute((1, 0, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 4])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7702)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(func.init_cond_mat[:, :, 4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7975)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(func.init_cond_mat[:, :, :4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    t, y, y0, t_mask, y_mask, eids = get_all(dat_folds[0]['val'])\n",
    "    func.set_init_cond(eids)\n",
    "    init_zeros = torch.zeros_like(func.init_cond)\n",
    "\n",
    "    pred_y = dto(func, init_zeros, t, method='euler_par', options={'step_size': step_size})\n",
    "    pred_y_final = (pred_y  + func.init_cond)[..., :func.dim]\n",
    "\n",
    "    loss = torch.mean(torch.abs(pred_y_final[y_mask] - y[y_mask]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0748,  0.1314,  0.0741, -0.2251,  0.2084,  0.0000,  0.5503,  0.0850],\n",
       "        [-1.0692,  1.0429,  0.0741, -1.0025,  0.4438, -0.1469,  0.4507, -0.0696],\n",
       "        [-0.3912, -0.1421,  0.0182, -0.6570,  0.1905,  0.0000,  0.2935, -0.1618],\n",
       "        [-0.1370,  0.1314,  0.3538,  1.4160,  0.0709, -0.2287,  0.3508, -0.5056],\n",
       "        [ 0.6680, -1.3271, -2.1075,  0.8114, -0.8754, -0.4185,  2.8251, -0.9914]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond[:5,0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0748,  0.1314,  0.0741, -0.2251],\n",
       "        [-1.0692,  1.0429,  0.0741, -1.0025],\n",
       "        [-0.3912, -0.1421,  0.0182, -0.6570],\n",
       "        [-0.1370,  0.1314,  0.3538,  1.4160],\n",
       "        [ 0.6680, -1.3271, -2.1075,  0.8114]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0[:5,0, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0748,  0.1314,  0.0741, -0.2251],\n",
       "        [ 0.2966,  0.3205,  0.4992,  0.1014],\n",
       "        [ 0.3616,  0.3970,  0.5153,  0.2271],\n",
       "        [ 0.3939,  0.4275,  0.5174,  0.2844],\n",
       "        [ 0.4475,  0.4661,  0.5184,  0.3721]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_final[:5, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0748,  0.1314,  0.0741, -0.2251],\n",
       "        [ 0.2867,  0.1314,  0.6335, -0.1387],\n",
       "        [ 0.3291,  0.1314, -0.1496,  0.0340],\n",
       "        [ 0.4985, -0.2332, -0.4853, -1.0889],\n",
       "        [-0.0523,  0.1314,  0.0741, -0.3115]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0050 | Total Loss 0.426231\n",
      "Iter 0100 | Total Loss 0.597094\n",
      "Iter 0150 | Total Loss 0.583271\n",
      "Iter 0200 | Total Loss 1.400030\n",
      "Iter 0250 | Total Loss 0.738257\n",
      "Iter 0300 | Total Loss 0.420469\n",
      "Iter 0350 | Total Loss 0.611337\n",
      "Iter 0400 | Total Loss 0.443519\n",
      "Iter 0450 | Total Loss 0.491005\n",
      "Iter 0500 | Total Loss 0.892621\n",
      "Iter 0550 | Total Loss 0.768308\n",
      "Iter 0600 | Total Loss 0.525871\n",
      "Iter 0650 | Total Loss 0.453953\n",
      "Iter 0700 | Total Loss 1.970526\n",
      "Iter 0750 | Total Loss 0.988136\n",
      "Iter 0800 | Total Loss 2.543571\n",
      "Iter 0850 | Total Loss 1.738551\n",
      "Iter 0900 | Total Loss 0.450546\n",
      "Iter 0950 | Total Loss 0.405119\n",
      "Iter 1000 | Total Loss 0.566877\n",
      "Iter 1050 | Total Loss 0.449112\n",
      "Iter 1100 | Total Loss 0.478447\n",
      "Iter 1150 | Total Loss 0.420794\n",
      "Iter 1200 | Total Loss 0.375969\n",
      "Iter 1250 | Total Loss 0.641680\n",
      "Iter 1300 | Total Loss 0.411319\n",
      "Iter 1350 | Total Loss 0.385653\n",
      "Iter 1400 | Total Loss 0.409560\n",
      "Iter 1450 | Total Loss 0.422992\n",
      "Iter 1500 | Total Loss 0.390408\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "\n",
    "start = time.time()\n",
    "for itr in range(1, niters + 1):\n",
    "    \n",
    "    t, y, y0, t_mask, y_mask, eids = get_batch(dat_dict, batch_size, itr+500)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    func.set_init_cond(eids)\n",
    "    init_zeros = torch.zeros_like(func.init_cond)\n",
    "    \n",
    "    pred_y = dto(func, init_zeros, t, method='euler_par', options={'step_size': step_size})\n",
    "    pred_y_final = (pred_y  + func.init_cond)[..., :func.dim]\n",
    "    \n",
    "    loss = torch.mean(torch.abs(pred_y_final[y_mask] - y[y_mask]))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if itr % test_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            print('Iter {:04d} | Total Loss {:.6f}'.format(itr, loss.item()))\n",
    "            ii += 1\n",
    "\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/cprd_ho2.pth'\n",
    "torch.save(func.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func1 = ode_models.HigherOrderOde(dat_dict,batch_size=batch_size, dim=4, order=2, hidden_size=50)\n",
    "# func1.load_state_dict(torch.load(model_path))\n",
    "# func1.eval()\n",
    "# func1.init_cond_mat.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.17963133653005"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end-start)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr=498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, y, y0, t_mask, y_mask, eids = get_batch(dat_dict, batch_size, itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8423206'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': tensor([0.0000, 3.1205, 4.7178]),\n",
       " 'x': tensor([[[[0.4524, 2.7864, 2.9481, 1.3142]]],\n",
       " \n",
       " \n",
       "         [[[0.1569, 1.9626, 1.4286, 0.2870]]],\n",
       " \n",
       " \n",
       "         [[[0.7479, 1.6880, 1.6537, 0.8006]]]])}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_dict['14260073']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4524, 2.7864, 2.9481, 1.3142]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5238)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.array([func.eid_to_id[x] for x in eids])\n",
    "id_torch = torch.from_numpy(idx)\n",
    "#  self.init_cond = self.init_cond_mat[id_torch, ...]\n",
    "id_torch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4512,  2.7882,  2.9492,  1.3124, -0.0830, -0.2435, -0.4933, -0.3075]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond_mat[5238]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1238, -0.6072, -1.0318,  0.8855, -0.1671,  0.3526,  0.2405, -0.1994]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7010, 1, 8])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_untrain = ode_models.HigherOrderOde(dat_dict,batch_size=batch_size, dim=4, order=2, hidden_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(func.init_cond_mat[..., :4] - func_untrain.init_cond_mat[..., :4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1154,  0.6854,  1.9798,  2.4262],\n",
       "        [-1.1180,  0.0436, -0.2041,  0.8874],\n",
       "        [ 0.4524, -0.5087, -0.8788, -0.2265],\n",
       "        [ 2.0107, -0.1345,  0.5280,  0.5414],\n",
       "        [ 0.1557, -0.3421,  0.3031, -0.1577]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond_mat[:5, 0, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0964,  0.6812,  1.9914,  2.4268],\n",
       "        [-1.1096,  0.0405, -0.2035,  0.8862],\n",
       "        [ 0.4524, -0.5087, -0.8788, -0.2265],\n",
       "        [ 2.0144, -0.1426,  0.5282,  0.5438],\n",
       "        [ 0.1569, -0.3256,  0.3031, -0.1409]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_untrain.init_cond_mat[:5, 0, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6105,  0.4214,  2.3506, -0.3816],\n",
       "        [-0.0939,  0.3392,  0.6464, -0.7820],\n",
       "        [-1.3570,  0.3796, -0.4085,  0.0888],\n",
       "        [-0.0635, -0.4829, -0.3766, -0.1169],\n",
       "        [-0.1704,  0.3768, -0.1794,  0.4243]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond_mat[:5, 0, -4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5927,  0.4283,  2.3702, -0.4005],\n",
       "        [-0.0888,  0.3464,  0.6390, -0.7918],\n",
       "        [-1.3570,  0.3796, -0.4085,  0.0888],\n",
       "        [-0.0617, -0.4903, -0.3837, -0.1250],\n",
       "        [-0.1813,  0.3930, -0.1933,  0.4411]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_untrain.init_cond_mat[:5, 0, -4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 500\n",
      "Processed: 1000\n",
      "Processed: 1500\n",
      "Processed: 2000\n",
      "Processed: 2500\n",
      "Processed: 3000\n",
      "Processed: 3500\n",
      "Processed: 4000\n",
      "Processed: 4500\n",
      "Processed: 5000\n",
      "Processed: 5500\n",
      "Processed: 6000\n",
      "Processed: 6500\n",
      "Processed: 7000\n"
     ]
    }
   ],
   "source": [
    "n_processed = 0\n",
    "step_size = 1./12\n",
    "\n",
    "s = time.time()\n",
    "for eid, v in dat_dict.items():\n",
    "    t = v['t']\n",
    "    x = v['x']\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    func.set_init_cond([eid])\n",
    "    init_zeros = torch.zeros_like(func.init_cond)\n",
    "    \n",
    "#     pred_y = odeint(func, init_zeros, t)\n",
    "    pred_y = dto(func, init_zeros, t, method='euler', options={'step_size': step_size})\n",
    "    \n",
    "    pred_y_final = pred_y  + func.init_cond\n",
    "    loss = torch.mean(torch.abs(pred_y_final[..., :func.dim] - x))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    n_processed += 1\n",
    "    \n",
    "    if n_processed % 500 == 0:\n",
    "        print('Processed:', n_processed)\n",
    "#     if n_processed > 100:\n",
    "#         break\n",
    "e = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175.36765384674072"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_zeros.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[100.0000,  91.0000, 128.0000,   6.4000, -11.1027,  -1.3878,   5.5513,\n",
       "           -2.6369]]], requires_grad=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.init_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = odeint(func, init_zeros, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HigherOrderOde' object has no attribute 'set_init_cond'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-66047e822195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_init_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0minit_zeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/alt/applic/user-maint/zq224/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HigherOrderOde' object has no attribute 'set_init_cond'"
     ]
    }
   ],
   "source": [
    "v = dat_dict['1092']\n",
    "\n",
    "t = v['t']\n",
    "x = v['x']\n",
    "\n",
    "optimizer.zero_grad()\n",
    "func.set_init_cond(eid, t, x)\n",
    "init_zeros = torch.zeros_like(func.init_cond)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = odeint(func, init_zeros, t)\n",
    "pred_y_final = pred_y + func.init_cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean(torch.abs(pred_y_final[..., :func.dim] - x))\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, ...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid_list = list(dat_dict.keys())\n",
    "eid_to_id = dict(zip(eid_list, range(len(eid_list))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': tensor([0.0000, 0.8548, 4.8959]),\n",
       " 'x': tensor([[[[ 86.0000,  86.0000, 174.0000,   7.6000]]],\n",
       " \n",
       " \n",
       "         [[[ 74.0000,  90.0000, 210.0000,   7.2000]]],\n",
       " \n",
       " \n",
       "         [[[ 88.0000,  82.0000, 140.0000,   5.6000]]]])}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_dict['1092']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': tensor([0.0000, 2.3781, 5.7644]),\n",
       " 'x': tensor([[[[ 62.0000,  79.0000, 135.0000,   5.8000]]],\n",
       " \n",
       " \n",
       "         [[[ 57.0000,  88.0000, 162.0000,   3.6000]]],\n",
       " \n",
       " \n",
       "         [[[ 74.0000,  78.0000, 146.0000,   4.8000]]]])}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_dict['3259']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1, 4])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
